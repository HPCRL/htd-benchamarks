----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 66	fail_ct: 4030	Time elapsed: 5.45
GA Iter: 0	Max score: 0.9978	Min score: 0.0315	#Pop: 66	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9773	#Pop: 128	#M+: 1396	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 24.21
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Done ]
----------------------------------------------------------------------
arc=sm_80
Computational DAG:
A = PLACEHOLDER [8192, 8192]
B = PLACEHOLDER [8192, 1]
matmul(i, j) += (A[i, k]*B[k, j])
C = PLACEHOLDER [8192, 1]
out(i, j) = (matmul[i, j] + C[i, j])

Lowered TIR:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((8192, 8192), "float32"), B: T.Buffer((8192, 1), "float32"), C: T.Buffer((8192, 1), "float32"), out: T.Buffer((8192, 1), "float32")):
        T.func_attr({"from_legacy_te_schedule": T.bool(True), "global_symbol": "main", "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 128)
        matmul = T.allocate([2], "float32", "local")
        A_shared = T.allocate([512], "float32", "shared")
        B_shared = T.allocate([8], "float32", "shared")
        threadIdx_x = T.launch_thread("threadIdx.x", 32)
        matmul_1 = T.Buffer((2,), data=matmul, scope="local", align=8)
        matmul_1[0] = T.float32(0)
        matmul_1[1] = T.float32(0)
        for k_outer_outer in range(1024):
            threadIdx_x_1 = T.env_thread("threadIdx.x")
            A_shared_1 = T.Buffer((512,), data=A_shared, scope="shared")
            A_1 = T.Buffer((67108864,), data=A.data)
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8]
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1 + 32] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8 + 32768]
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1 + 64] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8 + 65536]
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1 + 96] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8 + 98304]
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1 + 128] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8 + 131072]
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1 + 160] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8 + 163840]
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1 + 192] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8 + 196608]
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1 + 224] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8 + 229376]
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1 + 256] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8 + 262144]
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1 + 288] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8 + 294912]
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1 + 320] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8 + 327680]
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1 + 352] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8 + 360448]
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1 + 384] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8 + 393216]
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1 + 416] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8 + 425984]
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1 + 448] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8 + 458752]
            with T.launch_thread(threadIdx_x_1, 32):
                A_shared_1[threadIdx_x_1 + 480] = A_1[blockIdx_x * 524288 + threadIdx_x_1 // 8 * 8192 + k_outer_outer * 8 + threadIdx_x_1 % 8 + 491520]
            B_shared_1 = T.Buffer((8,), data=B_shared, scope="shared", align=32)
            with T.launch_thread("threadIdx.x", 32) as threadIdx_x_2:
                if T.likely(threadIdx_x_2 < 8):
                    B_1 = T.Buffer((8192,), data=B.data)
                    B_shared_1[threadIdx_x_2] = B_1[k_outer_outer * 8 + threadIdx_x_2]
            matmul_1[0] = matmul_1[0] + A_shared_1[threadIdx_x * 16] * B_shared_1[0]
            matmul_1[0] = matmul_1[0] + A_shared_1[threadIdx_x * 16 + 1] * B_shared_1[1]
            matmul_1[0] = matmul_1[0] + A_shared_1[threadIdx_x * 16 + 2] * B_shared_1[2]
            matmul_1[0] = matmul_1[0] + A_shared_1[threadIdx_x * 16 + 3] * B_shared_1[3]
            matmul_1[1] = matmul_1[1] + A_shared_1[threadIdx_x * 16 + 8] * B_shared_1[0]
            matmul_1[1] = matmul_1[1] + A_shared_1[threadIdx_x * 16 + 9] * B_shared_1[1]
            matmul_1[1] = matmul_1[1] + A_shared_1[threadIdx_x * 16 + 10] * B_shared_1[2]
            matmul_1[1] = matmul_1[1] + A_shared_1[threadIdx_x * 16 + 11] * B_shared_1[3]
            matmul_1[0] = matmul_1[0] + A_shared_1[threadIdx_x * 16 + 4] * B_shared_1[4]
            matmul_1[0] = matmul_1[0] + A_shared_1[threadIdx_x * 16 + 5] * B_shared_1[5]
            matmul_1[0] = matmul_1[0] + A_shared_1[threadIdx_x * 16 + 6] * B_shared_1[6]
            matmul_1[0] = matmul_1[0] + A_shared_1[threadIdx_x * 16 + 7] * B_shared_1[7]
            matmul_1[1] = matmul_1[1] + A_shared_1[threadIdx_x * 16 + 12] * B_shared_1[4]
            matmul_1[1] = matmul_1[1] + A_shared_1[threadIdx_x * 16 + 13] * B_shared_1[5]
            matmul_1[1] = matmul_1[1] + A_shared_1[threadIdx_x * 16 + 14] * B_shared_1[6]
            matmul_1[1] = matmul_1[1] + A_shared_1[threadIdx_x * 16 + 15] * B_shared_1[7]
        for i_inner in range(2):
            out_1 = T.Buffer((8192,), data=out.data)
            C_1 = T.Buffer((8192,), data=C.data)
            out_1[blockIdx_x * 64 + threadIdx_x * 2 + i_inner] = matmul_1[i_inner] + C_1[blockIdx_x * 64 + threadIdx_x * 2 + i_inner]
Equivalent python schedule:
matmul_i, matmul_j, matmul_k = tuple(matmul.op.axis) + tuple(matmul.op.reduce_axis)
out_i, out_j = tuple(out.op.axis) + tuple(out.op.reduce_axis)
matmul_i_o_i, matmul_i_i = s[matmul].split(matmul_i, factor=1)
matmul_i_o_o_i, matmul_i_o_i = s[matmul].split(matmul_i_o_i, factor=2)
matmul_i_o_o_o_i, matmul_i_o_o_i = s[matmul].split(matmul_i_o_o_i, factor=32)
matmul_i_o_o_o_o, matmul_i_o_o_o_i = s[matmul].split(matmul_i_o_o_o_i, factor=1)
matmul_j_o_i, matmul_j_i = s[matmul].split(matmul_j, factor=1)
matmul_j_o_o_i, matmul_j_o_i = s[matmul].split(matmul_j_o_i, factor=1)
matmul_j_o_o_o_i, matmul_j_o_o_i = s[matmul].split(matmul_j_o_o_i, factor=1)
matmul_j_o_o_o_o, matmul_j_o_o_o_i = s[matmul].split(matmul_j_o_o_o_i, factor=1)
matmul_k_o_i, matmul_k_i = s[matmul].split(matmul_k, factor=4)
matmul_k_o_o, matmul_k_o_i = s[matmul].split(matmul_k_o_i, factor=2)
s[matmul].reorder(matmul_i_o_o_o_o, matmul_j_o_o_o_o, matmul_i_o_o_o_i, matmul_j_o_o_o_i, matmul_i_o_o_i, matmul_j_o_o_i, matmul_k_o_o, matmul_k_o_i, matmul_i_o_i, matmul_j_o_i, matmul_k_i, matmul_i_i, matmul_j_i)
out_i_o_i, out_i_i = s[out].split(out_i, factor=2)
out_i_o_o_i, out_i_o_i = s[out].split(out_i_o_i, factor=32)
out_i_o_o_o, out_i_o_o_i = s[out].split(out_i_o_o_i, factor=1)
out_j_o_i, out_j_i = s[out].split(out_j, factor=1)
out_j_o_o_i, out_j_o_i = s[out].split(out_j_o_i, factor=1)
out_j_o_o_o, out_j_o_o_i = s[out].split(out_j_o_o_i, factor=1)
s[out].reorder(out_i_o_o_o, out_j_o_o_o, out_i_o_o_i, out_j_o_o_i, out_i_o_i, out_j_o_i, out_i_i, out_j_i)
s[matmul].compute_at(s[out], out_j_o_i)
B_shared = s.cache_read(B, "shared", [matmul])
B_shared_ax0, B_shared_ax1 = tuple(B_shared.op.axis)
s[B_shared].compute_at(s[matmul], matmul_k_o_o)
A_shared = s.cache_read(A, "shared", [matmul])
A_shared_ax0, A_shared_ax1 = tuple(A_shared.op.axis)
s[A_shared].compute_at(s[matmul], matmul_k_o_o)
out_i_o_o_o_j_o_o_o_fused = s[out].fuse(out_i_o_o_o, out_j_o_o_o)
s[out].bind(out_i_o_o_o_j_o_o_o_fused, te.thread_axis("blockIdx.x"))
out_i_o_o_i_j_o_o_i_fused = s[out].fuse(out_i_o_o_i, out_j_o_o_i)
s[out].bind(out_i_o_o_i_j_o_o_i_fused, te.thread_axis("vthread"))
out_i_o_i_j_o_i_fused = s[out].fuse(out_i_o_i, out_j_o_i)
s[out].bind(out_i_o_i_j_o_i_fused, te.thread_axis("threadIdx.x"))
B_shared_ax0_ax1_fused = s[B_shared].fuse(B_shared_ax0, B_shared_ax1)
B_shared_ax0_ax1_fused_o, B_shared_ax0_ax1_fused_i = s[B_shared].split(B_shared_ax0_ax1_fused, factor=1)
s[B_shared].vectorize(B_shared_ax0_ax1_fused_i)
B_shared_ax0_ax1_fused_o_o, B_shared_ax0_ax1_fused_o_i = s[B_shared].split(B_shared_ax0_ax1_fused_o, factor=32)
s[B_shared].bind(B_shared_ax0_ax1_fused_o_i, te.thread_axis("threadIdx.x"))
A_shared_ax0_ax1_fused = s[A_shared].fuse(A_shared_ax0, A_shared_ax1)
A_shared_ax0_ax1_fused_o, A_shared_ax0_ax1_fused_i = s[A_shared].split(A_shared_ax0_ax1_fused, factor=1)
s[A_shared].vectorize(A_shared_ax0_ax1_fused_i)
A_shared_ax0_ax1_fused_o_o, A_shared_ax0_ax1_fused_o_i = s[A_shared].split(A_shared_ax0_ax1_fused_o, factor=32)
s[A_shared].bind(A_shared_ax0_ax1_fused_o_i, te.thread_axis("threadIdx.x"))
s[matmul].pragma(matmul_i_o_o_o_o, "auto_unroll_max_step", 64)
s[matmul].pragma(matmul_i_o_o_o_o, "unroll_explicit", True)

Equivalent CUDA code:

#if (((__CUDACC_VER_MAJOR__ == 11) && (__CUDACC_VER_MINOR__ >= 4)) || \
     (__CUDACC_VER_MAJOR__ > 11))
#define TVM_ENABLE_L2_PREFETCH 1
#else
#define TVM_ENABLE_L2_PREFETCH 0
#endif

#ifdef _WIN32
  using uint = unsigned int;
  using uchar = unsigned char;
  using ushort = unsigned short;
  using int64_t = long long;
  using uint64_t = unsigned long long;
#else
  #define uint unsigned int
  #define uchar unsigned char
  #define ushort unsigned short
  #define int64_t long long
  #define uint64_t unsigned long long
#endif
extern "C" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ A, float* __restrict__ B, float* __restrict__ C, float* __restrict__ out) {
  float matmul[2];
  __shared__ float A_shared[512];
  __shared__ float B_shared[8];
  matmul[0] = 0.000000e+00f;
  matmul[1] = 0.000000e+00f;
  for (int k_outer_outer = 0; k_outer_outer < 1024; ++k_outer_outer) {
    __syncthreads();
    A_shared[((int)threadIdx.x)] = A[((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7))];
    A_shared[(((int)threadIdx.x) + 32)] = A[(((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7)) + 32768)];
    A_shared[(((int)threadIdx.x) + 64)] = A[(((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7)) + 65536)];
    A_shared[(((int)threadIdx.x) + 96)] = A[(((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7)) + 98304)];
    A_shared[(((int)threadIdx.x) + 128)] = A[(((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7)) + 131072)];
    A_shared[(((int)threadIdx.x) + 160)] = A[(((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7)) + 163840)];
    A_shared[(((int)threadIdx.x) + 192)] = A[(((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7)) + 196608)];
    A_shared[(((int)threadIdx.x) + 224)] = A[(((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7)) + 229376)];
    A_shared[(((int)threadIdx.x) + 256)] = A[(((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7)) + 262144)];
    A_shared[(((int)threadIdx.x) + 288)] = A[(((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7)) + 294912)];
    A_shared[(((int)threadIdx.x) + 320)] = A[(((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7)) + 327680)];
    A_shared[(((int)threadIdx.x) + 352)] = A[(((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7)) + 360448)];
    A_shared[(((int)threadIdx.x) + 384)] = A[(((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7)) + 393216)];
    A_shared[(((int)threadIdx.x) + 416)] = A[(((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7)) + 425984)];
    A_shared[(((int)threadIdx.x) + 448)] = A[(((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7)) + 458752)];
    A_shared[(((int)threadIdx.x) + 480)] = A[(((((((int)blockIdx.x) * 524288) + ((((int)threadIdx.x) >> 3) * 8192)) + (k_outer_outer * 8)) + (((int)threadIdx.x) & 7)) + 491520)];
    if (((int)threadIdx.x) < 8) {
      B_shared[((int)threadIdx.x)] = B[((k_outer_outer * 8) + ((int)threadIdx.x))];
    }
    __syncthreads();
    matmul[0] = (matmul[0] + (A_shared[(((int)threadIdx.x) * 16)] * B_shared[0]));
    matmul[0] = (matmul[0] + (A_shared[((((int)threadIdx.x) * 16) + 1)] * B_shared[1]));
    matmul[0] = (matmul[0] + (A_shared[((((int)threadIdx.x) * 16) + 2)] * B_shared[2]));
    matmul[0] = (matmul[0] + (A_shared[((((int)threadIdx.x) * 16) + 3)] * B_shared[3]));
    matmul[1] = (matmul[1] + (A_shared[((((int)threadIdx.x) * 16) + 8)] * B_shared[0]));
    matmul[1] = (matmul[1] + (A_shared[((((int)threadIdx.x) * 16) + 9)] * B_shared[1]));
    matmul[1] = (matmul[1] + (A_shared[((((int)threadIdx.x) * 16) + 10)] * B_shared[2]));
    matmul[1] = (matmul[1] + (A_shared[((((int)threadIdx.x) * 16) + 11)] * B_shared[3]));
    matmul[0] = (matmul[0] + (A_shared[((((int)threadIdx.x) * 16) + 4)] * B_shared[4]));
    matmul[0] = (matmul[0] + (A_shared[((((int)threadIdx.x) * 16) + 5)] * B_shared[5]));
    matmul[0] = (matmul[0] + (A_shared[((((int)threadIdx.x) * 16) + 6)] * B_shared[6]));
    matmul[0] = (matmul[0] + (A_shared[((((int)threadIdx.x) * 16) + 7)] * B_shared[7]));
    matmul[1] = (matmul[1] + (A_shared[((((int)threadIdx.x) * 16) + 12)] * B_shared[4]));
    matmul[1] = (matmul[1] + (A_shared[((((int)threadIdx.x) * 16) + 13)] * B_shared[5]));
    matmul[1] = (matmul[1] + (A_shared[((((int)threadIdx.x) * 16) + 14)] * B_shared[6]));
    matmul[1] = (matmul[1] + (A_shared[((((int)threadIdx.x) * 16) + 15)] * B_shared[7]));
  }
  for (int i_inner = 0; i_inner < 2; ++i_inner) {
    out[(((((int)blockIdx.x) * 64) + (((int)threadIdx.x) * 2)) + i_inner)] = (matmul[i_inner] + C[(((((int)blockIdx.x) * 64) + (((int)threadIdx.x) * 2)) + i_inner)]);
  }
}


